{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "import math\n",
    "import time\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch import nn\n",
    "from torch.utils.data import IterableDataset\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=1)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DATA_DIR = 'data/'\n",
    "\n",
    "SRC_VOCAB_FILE = [f'{DATA_DIR}/bpecodes', f'{DATA_DIR}/dict.ru.txt']\n",
    "TRG_VOCAB_FILE = [f'{DATA_DIR}/bpecodes', f'{DATA_DIR}/dict.en.txt']\n",
    "\n",
    "RU_DATA = f'{DATA_DIR}/train.ru'\n",
    "EN_DATA = f'{DATA_DIR}/train.en'\n",
    "\n",
    "MAX_SEQ_LEN = 255\n",
    "PAD_ID = 1\n",
    "BOUND_ID = 2\n",
    "\n",
    "# model params\n",
    "enc_ffn_dims = 8192\n",
    "dec_ffn_dims = 4096\n",
    "d_model = 1024\n",
    "heads = 16\n",
    "N = 6\n",
    "WARM_UP_STEPS = 16000\n",
    "INIT_LR = 2\n",
    "\n",
    "EPOCHS = 10\n",
    "BATCH_SIZE = 64\n",
    "\n",
    "DEVICE = torch.device('cuda:1' if torch.cuda.is_available() else 'cpu')\n",
    "DEVICE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PositionalEncoder(nn.Module):\n",
    "    def __init__(self, d_model, max_seq_len = 256):\n",
    "        super().__init__()\n",
    "        self.d_model = d_model\n",
    "\n",
    "        half_dim = d_model // 2\n",
    "        pe = math.log(10000) / (half_dim - 1)\n",
    "        pe = torch.exp(torch.arange(half_dim, dtype=torch.float) * -pe)\n",
    "        pe = torch.arange(max_seq_len, dtype=torch.float).unsqueeze(1) * pe.unsqueeze(0)\n",
    "        pe = torch.cat([torch.sin(pe), torch.cos(pe)], dim=1).view(max_seq_len, -1)\n",
    "        \n",
    "        pe = pe.unsqueeze(0)\n",
    "        self.register_buffer('pe', pe)\n",
    " \n",
    "    \n",
    "    def forward(self, x):\n",
    "        length = x.size(1) + 2\n",
    "        return x + self.pe[:, 2:length]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def attention(q, k, v, d_k, mask=None, dropout=None):\n",
    "    \n",
    "    scores = torch.matmul(q, k.transpose(-2, -1)) /  np.sqrt(d_k)\n",
    "    if mask is not None:\n",
    "        mask = mask.unsqueeze(1)\n",
    "        scores = scores.masked_fill(mask == 0, -1e9)\n",
    "    scores = F.softmax(scores, dim=-1)\n",
    "    \n",
    "    if dropout is not None:\n",
    "        scores = dropout(scores)\n",
    "        \n",
    "    output = torch.matmul(scores, v)\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiHeadAttention(nn.Module):\n",
    "    def __init__(self, heads, d_model, dropout = 0.1):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.d_model = d_model\n",
    "        self.d_k = d_model // heads\n",
    "        self.h = heads\n",
    "        \n",
    "        self.q_linear = nn.Linear(d_model, d_model)\n",
    "        self.v_linear = nn.Linear(d_model, d_model)\n",
    "        self.k_linear = nn.Linear(d_model, d_model)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.out = nn.Linear(d_model, d_model)\n",
    "    \n",
    "    def forward(self, q, k, v, mask=None):\n",
    "        \n",
    "        bs = q.size(0)\n",
    "                \n",
    "        k = self.k_linear(k).view(bs, -1, self.h, self.d_k)\n",
    "        q = self.q_linear(q).view(bs, -1, self.h, self.d_k)\n",
    "        v = self.v_linear(v).view(bs, -1, self.h, self.d_k)\n",
    "        \n",
    "        k = k.transpose(1,2)\n",
    "        q = q.transpose(1,2)\n",
    "        v = v.transpose(1,2)\n",
    "        scores = attention(q, k, v, self.d_k, mask, self.dropout)\n",
    "        \n",
    "        concat = scores.transpose(1,2).contiguous().view(bs, -1, self.d_model)\n",
    "        \n",
    "        output = self.out(concat)\n",
    "    \n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeedForward(nn.Module):\n",
    "    def __init__(self, d_model, d_ff, dropout = 0.1):\n",
    "        super().__init__() \n",
    "        self.dropout = dropout\n",
    "        self.linear_1 = nn.Linear(d_model, d_ff)\n",
    "        self.linear_2 = nn.Linear(d_ff, d_model)\n",
    "    def forward(self, x):\n",
    "        x = F.dropout(F.relu(self.linear_1(x)), p = self.dropout, training = self.training)\n",
    "        x = self.linear_2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderLayer(nn.Module):\n",
    "    def __init__(self, d_model, heads, ffn_dim, dropout = 0.1):\n",
    "        super().__init__()\n",
    "        self.dropout = dropout\n",
    "        self.norm_1 = nn.LayerNorm(d_model)\n",
    "        self.norm_2 = nn.LayerNorm(d_model)\n",
    "        self.attn = MultiHeadAttention(heads, d_model)\n",
    "        self.ff = FeedForward(d_model, ffn_dim)\n",
    "        \n",
    "    def forward(self, x, mask):\n",
    "        x = x + F.dropout(self.attn(x, x, x, mask), p = self.dropout, training = self.training)\n",
    "        x = self.norm_1(x)\n",
    "        x = x + F.dropout(self.ff(x), p = self.dropout, training = self.training)\n",
    "        x = self.norm_2(x)\n",
    "        return x\n",
    "\n",
    "class DecoderLayer(nn.Module):\n",
    "    def __init__(self, d_model, heads, ffn_dim, dropout=0.1):\n",
    "        super().__init__()\n",
    "        self.dropout = dropout\n",
    "        self.norm_1 = nn.LayerNorm(d_model)\n",
    "        self.norm_2 = nn.LayerNorm(d_model)\n",
    "        self.norm_3 = nn.LayerNorm(d_model)\n",
    "        self.attn_1 = MultiHeadAttention(heads, d_model)\n",
    "        self.attn_2 = MultiHeadAttention(heads, d_model)\n",
    "        self.ff = FeedForward(d_model, ffn_dim)\n",
    "        \n",
    "    def forward(self, x, e_outputs, src_mask, trg_mask):\n",
    "        x = x + F.dropout(self.attn_1(x, x, x, trg_mask), p = self.dropout, training = self.training)\n",
    "        x = self.norm_1(x)\n",
    "        x = x + F.dropout(self.attn_2(x, e_outputs, e_outputs, src_mask), p = self.dropout, training = self.training)\n",
    "        x = self.norm_2(x)\n",
    "        x = x + F.dropout(self.ff(x), p = self.dropout, training = self.training)\n",
    "        x = self.norm_3(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    def __init__(self, vocab_size, d_model, N, heads, ffn_dim):\n",
    "        super().__init__()\n",
    "        self.N = N\n",
    "        self.d_model = d_model\n",
    "        self.embed = nn.Embedding(vocab_size, d_model, padding_idx=1)\n",
    "        self.pe = PositionalEncoder(d_model)\n",
    "        self.layers = nn.ModuleList([EncoderLayer(d_model, heads, ffn_dim) for _ in range(N)])\n",
    "    def forward(self, src, mask):\n",
    "        x = self.embed(src) * np.sqrt(self.d_model)\n",
    "        x = self.pe(x)\n",
    "        for i in range(N):\n",
    "            x = self.layers[i](x, mask)\n",
    "        return x\n",
    "    \n",
    "class Decoder(nn.Module):\n",
    "    def __init__(self, vocab_size, d_model, N, heads, ffn_dim):\n",
    "        super().__init__()\n",
    "        self.N = N\n",
    "        self.d_model = d_model\n",
    "        self.embed = nn.Embedding(vocab_size, d_model, padding_idx=1)\n",
    "        self.pe = PositionalEncoder(d_model)\n",
    "        self.layers = nn.ModuleList([DecoderLayer(d_model, heads, ffn_dim) for _ in range(N)])\n",
    "    def forward(self, trg, e_outputs, src_mask, trg_mask):\n",
    "        x = self.embed(trg) * np.sqrt(self.d_model)\n",
    "        x = self.pe(x)\n",
    "        for i in range(self.N):\n",
    "            x = self.layers[i](x, e_outputs, src_mask, trg_mask)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Transformer(nn.Module):\n",
    "    def __init__(self, src_vocab_size, trg_vocab_size, d_model, N, heads, enc_ffn_dim, dec_ffn_dim):\n",
    "        super().__init__()\n",
    "        self.encoder = Encoder(src_vocab_size, d_model, N, heads, enc_ffn_dim)\n",
    "        self.decoder = Decoder(trg_vocab_size, d_model, N, heads, dec_ffn_dim)\n",
    "    def forward(self, src, trg, src_mask, trg_mask):\n",
    "        e_outputs = self.encoder(src, src_mask)\n",
    "        d_output = self.decoder(trg, e_outputs, src_mask, trg_mask)\n",
    "        output = F.linear(d_output, self.decoder.embed.weight)\n",
    "        return output\n",
    "    \n",
    "    def out(self, trg, e_outputs, src_mask, trg_mask):\n",
    "        d_output = self.decoder(trg, e_outputs, src_mask, trg_mask)\n",
    "        output = F.linear(d_output, self.decoder.embed.weight)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Tokenizer:\n",
    "    \n",
    "    def __init__(self, bpe_file: str, vocab_file: str):\n",
    "        import fastBPE\n",
    "        from sacremoses import MosesDetokenizer, MosesTokenizer\n",
    "        \n",
    "        self.bpe = fastBPE.fastBPE(bpe_file)\n",
    "        self.tokenizer = MosesTokenizer('ru')\n",
    "        self.detokenizer = MosesDetokenizer('en')\n",
    "        \n",
    "        tmp = open(vocab_file, encoding='utf-8').read().split('\\n')\n",
    "        tmp = [x.split()[0] for x in tmp[:-1]]\n",
    "        self.vocab = ['<sos>', '<pad>', '<eos>', '<unk>'] + tmp\n",
    "        self.t2i = {t : i for i, t in enumerate(self.vocab)}\n",
    "    \n",
    "    def encode(self, sent: str, add_eos = False):\n",
    "        sent = self.tokenizer.tokenize(sent, aggressive_dash_splits=True, return_str=True)\n",
    "        tokens = self.bpe.apply([sent])[0].split()\n",
    "        tokens = [self.t2i[t] if t in self.t2i else self.t2i['<unk>'] for t in tokens]\n",
    "        if add_eos:\n",
    "            tokens += [self.t2i['<eos>']]\n",
    "        return tokens\n",
    "    \n",
    "    def decode(self, tokens: list):\n",
    "        sent = [self.vocab[t] for t in tokens]\n",
    "        sent = ' '.join(sent)\n",
    "        sent = (sent + ' ').replace('@@ ', '').rstrip()\n",
    "        sent = self.detokenizer.detokenize(sent.split())\n",
    "        return sent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NMT_dataset(IterableDataset):\n",
    "\n",
    "    def __init__(self, ru_data, en_data):\n",
    "        self.ru_data = ru_data\n",
    "        self.en_data = en_data\n",
    "        self.src_tokenizer = Tokenizer(*SRC_VOCAB_FILE)\n",
    "        self.trg_tokenizer = Tokenizer(*TRG_VOCAB_FILE)\n",
    "    \n",
    "    def src_line_mapper(self, line):\n",
    "        line = line.replace('\\n', '')\n",
    "        tokens = self.src_tokenizer.encode(line, True)\n",
    "        return tokens\n",
    "    \n",
    "    def trg_line_mapper(self, line):\n",
    "        line = line.replace('\\n', '')\n",
    "        tokens = self.trg_tokenizer.encode(line, True)\n",
    "        return tokens\n",
    "    \n",
    "    def __iter__(self):\n",
    "\n",
    "        ru_iter = open(self.ru_data, 'r', encoding='utf-8')\n",
    "        en_iter = open(self.en_data, 'r', encoding='utf-8')\n",
    "\n",
    "        mapped_ru_iter = map(self.src_line_mapper, ru_iter)\n",
    "        mapped_en_iter = map(self.trg_line_mapper, en_iter)\n",
    "        \n",
    "        ru_en_iter = zip(mapped_ru_iter, mapped_en_iter)\n",
    "        \n",
    "        return ru_en_iter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pad_batch(batch):\n",
    "    max_src_len = max(len(x) for x, _ in batch)\n",
    "    max_trg_len = max(len(y) for _, y in batch)\n",
    "    max_src_len = min(max_src_len, MAX_SEQ_LEN)\n",
    "    max_trg_len = min(max_trg_len, MAX_SEQ_LEN)\n",
    "    \n",
    "    src_batch = [x[:max_src_len] for x, _ in batch]\n",
    "    trg_batch = [y[:max_trg_len] for _, y in batch]\n",
    "    \n",
    "    src_batch = [np.pad(x, (0, max_src_len - len(x)), constant_values = PAD_ID) for x in src_batch]\n",
    "    trg_batch = [np.pad(y, (0, max_trg_len - len(y)), constant_values = PAD_ID) for y in trg_batch]\n",
    "    return torch.tensor(src_batch, dtype=torch.long), torch.tensor(trg_batch, dtype=torch.long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nopeak_mask(size):\n",
    "    np_mask = np.triu(np.ones((1, size, size)), k=1).astype('uint8')\n",
    "    np_mask = torch.from_numpy(np_mask) == 0\n",
    "    return np_mask.to(DEVICE)\n",
    "\n",
    "def create_masks(src, trg):\n",
    "    \n",
    "    src_mask = (src != PAD_ID).unsqueeze(-2)\n",
    "\n",
    "    if trg is not None:\n",
    "        trg_mask = (trg != PAD_ID).unsqueeze(-2)\n",
    "        size = trg.size(1)\n",
    "        np_mask = nopeak_mask(size).to(DEVICE)\n",
    "        trg_mask = trg_mask & np_mask\n",
    "    else:\n",
    "        trg_mask = None\n",
    "        \n",
    "    return src_mask, trg_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = NMT_dataset(RU_DATA, EN_DATA)\n",
    "dataloader = DataLoader(dataset, batch_size = BATCH_SIZE, collate_fn=pad_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "src_vocab_size = len(dataset.src_tokenizer.vocab)\n",
    "trg_vocab_size = len(dataset.trg_tokenizer.vocab)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Transformer(src_vocab_size, trg_vocab_size, d_model, N, heads, enc_ffn_dims, dec_ffn_dims).to(DEVICE)\n",
    "for p in model.parameters():\n",
    "    if p.dim() > 1:\n",
    "        nn.init.xavier_uniform_(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_lr(step):\n",
    "    lr = INIT_LR\n",
    "    lr *= d_model ** (-0.5)\n",
    "    lr *= min(1.0, step / WARM_UP_STEPS)\n",
    "    lr *= 1 / np.sqrt(max(step, WARM_UP_STEPS))\n",
    "    return lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "optim = torch.optim.Adam(model.parameters(), lr=INIT_LR, betas=(0.9, 0.98), eps=1e-9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "scheduler = torch.optim.lr_scheduler.LambdaLR(optim, get_lr, last_epoch=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "\n",
    "logging.basicConfig(level=logging.DEBUG)\n",
    "LOGGER = logging.getLogger()\n",
    "FH = logging.FileHandler(\"train.log\", \"w\", encoding=\"utf8\")\n",
    "FH.setFormatter(logging.Formatter(\"%(asctime)s %(message)s\"))\n",
    "LOGGER.setLevel(logging.DEBUG)\n",
    "LOGGER.addHandler(FH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "def train_model(epochs, print_every=10):\n",
    "    \n",
    "    model.train()\n",
    "    \n",
    "    start = time.time()\n",
    "    temp = start\n",
    "    \n",
    "    total_loss = 0\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        for i, (src, trg) in tqdm(enumerate(dataloader)):\n",
    "            scheduler.step()\n",
    "            \n",
    "            src = src.to(DEVICE)\n",
    "            trg = trg.to(DEVICE)\n",
    "            \n",
    "            trg_input = F.pad(trg[:, :-1], (1, 0), value=BOUND_ID)\n",
    "            src_mask, trg_mask = create_masks(src, trg_input)\n",
    "            preds = model(src, trg_input, src_mask, trg_mask)\n",
    "            \n",
    "            optim.zero_grad()\n",
    "            loss = F.cross_entropy(preds.view(-1, preds.size(-1)), trg.view(-1), ignore_index=PAD_ID)\n",
    "            loss.backward()\n",
    "            optim.step()\n",
    "            \n",
    "            total_loss += loss\n",
    "            \n",
    "            if (i + 1) % print_every == 0:\n",
    "                loss_avg = total_loss / print_every\n",
    "                LOGGER.info(f\"iter = {i + 1}, lr = {scheduler.get_lr()[0]}, loss = {loss_avg}\")\n",
    "                total_loss = 0\n",
    "            if (i + 1) % 100 == 0:\n",
    "                tokens = np.argmax(F.softmax(preds, -1).data.tolist(), 2)\n",
    "                LOGGER.info(f'Prediction: {dataset.tokenizer.decode(tokens[0])}')\n",
    "                LOGGER.info(f'True: {dataset.tokenizer.decode(trg[0].data.tolist())}')\n",
    "            if (i + 1) % 20000 == 0:\n",
    "                torch.save(model.state_dict(), f'model.epoch{epoch}it{i+1}.pt')\n",
    "        \n",
    "        torch.save(model.state_dict(), f'model.epoch{epoch}.it{i+1}.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# train_model(EPOCHS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.save(model.state_dict(), f'model.pt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PATH = \"model.pt\"\n",
    "model = Transformer(src_vocab_size, trg_vocab_size, d_model, N, heads, enc_ffn_dims, dec_ffn_dims).to(DEVICE)\n",
    "model.load_state_dict(torch.load(PATH, map_location=DEVICE))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Beam search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "def init_vars(sentence, model, K):\n",
    "    \n",
    "    src_mask = (sentence != PAD_ID)\n",
    "    e_output = model.encoder(sentence, src_mask)\n",
    "            \n",
    "    out = model.out(torch.LongTensor([[BOUND_ID]]).to(DEVICE), \n",
    "                    e_output, src_mask, \n",
    "                    nopeak_mask(1))\n",
    "    out = F.softmax(out, -1)\n",
    "    \n",
    "    probs, ix = out[:, -1].data.topk(K)\n",
    "    log_scores = torch.Tensor([math.log(prob) for prob in probs.data[0]]).unsqueeze(0).to(DEVICE)\n",
    "    \n",
    "    outputs = torch.zeros(K, MAX_SEQ_LEN).long().to(DEVICE)\n",
    "    outputs[:, 0] = BOUND_ID\n",
    "    outputs[:, 1] = ix[0]\n",
    "    \n",
    "    e_outputs = torch.zeros(K, e_output.size(-2),e_output.size(-1)).to(DEVICE)\n",
    "    e_outputs[:, :] = e_output[0]\n",
    "    \n",
    "    return outputs, e_outputs, log_scores\n",
    "\n",
    "def k_best_outputs(outputs, out, log_scores, i, k):\n",
    "    \n",
    "    probs, ix = out[:, -1].data.topk(k)\n",
    "    log_probs = torch.Tensor([math.log(p) for p in probs.data.view(-1)]).view(k, -1).to(DEVICE) + log_scores.transpose(0,1)\n",
    "    log_probs = log_probs.to(DEVICE)\n",
    "    \n",
    "    k_probs, k_ix = log_probs.view(-1).topk(k)\n",
    "    \n",
    "    row = k_ix // k\n",
    "    col = k_ix % k\n",
    "\n",
    "    outputs[:, :i] = outputs[row, :i]\n",
    "    outputs[:, i] = ix[row, col]\n",
    "\n",
    "    log_scores = k_probs.unsqueeze(0)\n",
    "    \n",
    "    return outputs, log_scores\n",
    "\n",
    "def beam_search(sentence, model, K = 10):    \n",
    "    \n",
    "    outputs, e_outputs, log_scores = init_vars(sentence, model, K)\n",
    "    src_mask = (sentence != PAD_ID).to(DEVICE)\n",
    "    ind = None\n",
    "    for i in range(2, MAX_SEQ_LEN):\n",
    "    \n",
    "        trg_mask = nopeak_mask(i)\n",
    "\n",
    "        out = model.out(outputs[:,:i], e_outputs, src_mask, trg_mask)\n",
    "\n",
    "        out = F.softmax(out, dim=-1)\n",
    "    \n",
    "        outputs, log_scores = k_best_outputs(outputs, out, log_scores, i, K)\n",
    "        \n",
    "        sentence_lengths = torch.zeros(len(outputs), dtype=torch.long).to(DEVICE)\n",
    "        \n",
    "        ones = (outputs==BOUND_ID).nonzero()\n",
    "        for vec in ones:\n",
    "            i = vec[0]\n",
    "            if sentence_lengths[i] == 0:\n",
    "                sentence_lengths[i] = vec[1]\n",
    "        num_finished_sentences = len([s for s in sentence_lengths if s > 0])\n",
    "        if num_finished_sentences == K:\n",
    "            alpha = 0.6\n",
    "            div = 1/(sentence_lengths.type_as(log_scores)**alpha)\n",
    "            _, ind = torch.max(log_scores * div, 1)\n",
    "            ind = ind.data[0]\n",
    "            break\n",
    "        \n",
    "    if ind is None:\n",
    "        length = (outputs[0] == BOUND_ID).nonzero()\n",
    "        if len(length) != 0:\n",
    "            length = length[1]\n",
    "        else:\n",
    "            length = 10\n",
    "        res = outputs[0][1:length].data.tolist()\n",
    "        return dataset.trg_tokenizer.decode(res)\n",
    "    \n",
    "    else:\n",
    "        length = (outputs[ind] == BOUND_ID).nonzero()[1]\n",
    "        res = outputs[ind][1:length].data.tolist()\n",
    "        return dataset.trg_tokenizer.decode(res)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Transformer(\n",
       "  (encoder): Encoder(\n",
       "    (embed): Embedding(31232, 1024, padding_idx=1)\n",
       "    (pe): PositionalEncoder()\n",
       "    (layers): ModuleList(\n",
       "      (0): EncoderLayer(\n",
       "        (norm_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        (norm_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): MultiHeadAttention(\n",
       "          (q_linear): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (v_linear): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (k_linear): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (out): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        )\n",
       "        (ff): FeedForward(\n",
       "          (linear_1): Linear(in_features=1024, out_features=8192, bias=True)\n",
       "          (linear_2): Linear(in_features=8192, out_features=1024, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (1): EncoderLayer(\n",
       "        (norm_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        (norm_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): MultiHeadAttention(\n",
       "          (q_linear): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (v_linear): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (k_linear): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (out): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        )\n",
       "        (ff): FeedForward(\n",
       "          (linear_1): Linear(in_features=1024, out_features=8192, bias=True)\n",
       "          (linear_2): Linear(in_features=8192, out_features=1024, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (2): EncoderLayer(\n",
       "        (norm_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        (norm_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): MultiHeadAttention(\n",
       "          (q_linear): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (v_linear): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (k_linear): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (out): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        )\n",
       "        (ff): FeedForward(\n",
       "          (linear_1): Linear(in_features=1024, out_features=8192, bias=True)\n",
       "          (linear_2): Linear(in_features=8192, out_features=1024, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (3): EncoderLayer(\n",
       "        (norm_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        (norm_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): MultiHeadAttention(\n",
       "          (q_linear): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (v_linear): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (k_linear): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (out): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        )\n",
       "        (ff): FeedForward(\n",
       "          (linear_1): Linear(in_features=1024, out_features=8192, bias=True)\n",
       "          (linear_2): Linear(in_features=8192, out_features=1024, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (4): EncoderLayer(\n",
       "        (norm_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        (norm_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): MultiHeadAttention(\n",
       "          (q_linear): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (v_linear): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (k_linear): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (out): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        )\n",
       "        (ff): FeedForward(\n",
       "          (linear_1): Linear(in_features=1024, out_features=8192, bias=True)\n",
       "          (linear_2): Linear(in_features=8192, out_features=1024, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (5): EncoderLayer(\n",
       "        (norm_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        (norm_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): MultiHeadAttention(\n",
       "          (q_linear): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (v_linear): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (k_linear): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (out): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        )\n",
       "        (ff): FeedForward(\n",
       "          (linear_1): Linear(in_features=1024, out_features=8192, bias=True)\n",
       "          (linear_2): Linear(in_features=8192, out_features=1024, bias=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (decoder): Decoder(\n",
       "    (embed): Embedding(31640, 1024, padding_idx=1)\n",
       "    (pe): PositionalEncoder()\n",
       "    (layers): ModuleList(\n",
       "      (0): DecoderLayer(\n",
       "        (norm_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        (norm_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        (norm_3): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn_1): MultiHeadAttention(\n",
       "          (q_linear): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (v_linear): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (k_linear): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (out): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        )\n",
       "        (attn_2): MultiHeadAttention(\n",
       "          (q_linear): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (v_linear): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (k_linear): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (out): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        )\n",
       "        (ff): FeedForward(\n",
       "          (linear_1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (linear_2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (1): DecoderLayer(\n",
       "        (norm_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        (norm_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        (norm_3): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn_1): MultiHeadAttention(\n",
       "          (q_linear): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (v_linear): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (k_linear): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (out): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        )\n",
       "        (attn_2): MultiHeadAttention(\n",
       "          (q_linear): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (v_linear): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (k_linear): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (out): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        )\n",
       "        (ff): FeedForward(\n",
       "          (linear_1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (linear_2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (2): DecoderLayer(\n",
       "        (norm_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        (norm_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        (norm_3): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn_1): MultiHeadAttention(\n",
       "          (q_linear): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (v_linear): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (k_linear): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (out): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        )\n",
       "        (attn_2): MultiHeadAttention(\n",
       "          (q_linear): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (v_linear): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (k_linear): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (out): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        )\n",
       "        (ff): FeedForward(\n",
       "          (linear_1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (linear_2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (3): DecoderLayer(\n",
       "        (norm_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        (norm_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        (norm_3): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn_1): MultiHeadAttention(\n",
       "          (q_linear): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (v_linear): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (k_linear): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (out): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        )\n",
       "        (attn_2): MultiHeadAttention(\n",
       "          (q_linear): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (v_linear): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (k_linear): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (out): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        )\n",
       "        (ff): FeedForward(\n",
       "          (linear_1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (linear_2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (4): DecoderLayer(\n",
       "        (norm_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        (norm_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        (norm_3): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn_1): MultiHeadAttention(\n",
       "          (q_linear): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (v_linear): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (k_linear): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (out): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        )\n",
       "        (attn_2): MultiHeadAttention(\n",
       "          (q_linear): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (v_linear): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (k_linear): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (out): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        )\n",
       "        (ff): FeedForward(\n",
       "          (linear_1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (linear_2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (5): DecoderLayer(\n",
       "        (norm_1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        (norm_2): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        (norm_3): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn_1): MultiHeadAttention(\n",
       "          (q_linear): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (v_linear): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (k_linear): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (out): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        )\n",
       "        (attn_2): MultiHeadAttention(\n",
       "          (q_linear): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (v_linear): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (k_linear): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (out): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "        )\n",
       "        (ff): FeedForward(\n",
       "          (linear_1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (linear_2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def translate(sent):\n",
    "    sent = torch.LongTensor([dataset.src_line_mapper(sent)]).to(DEVICE)\n",
    "    return beam_search(sent, model, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"I'm tired of doing this housework\""
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "translate('Я устал делать эту домашку')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = open('data/eval-ru-100.txt', encoding='utf-8').read().split('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.autonotebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "864013910956426f84325373fcce7fab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "trans = [translate(x) for x in tqdm(data)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20913"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "open('answer.txt', 'w', encoding='utf-8').write('\\n'.join(trans))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "52.508918591346166\n"
     ]
    }
   ],
   "source": [
    "import sacrebleu\n",
    "refs = [open('data/truth-100.txt', encoding='utf-8').read().split('\\n')]\n",
    "bleu = sacrebleu.corpus_bleu(trans, refs)\n",
    "print(bleu.score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
